RET-LLM: Towards a General Read-Write Memory for Large Language
Models
Note: This concept paper outlines an initial methodology, now evolved and thoroughly evaluated in MEMLLM.†
Ali Modarressi1,2⋆Ayyoob Imani1,2⋆Mohsen Fayyaz3 Hinrich Schütze1,2
1Center for Information and Language Processing, LMU Munich, Germany
2Munich Center for Machine Learning, Germany
3Microsoft, Berlin, Germany
{amodaresi, ayyoob}@cis.lmu.de
Abstract
Large language models (LLMs) have signifi-
cantly advanced the field of natural language
processing (NLP) through their extensive pa-
rameters and comprehensive data utilization.
However, existing LLMs lack a dedicated mem-
ory unit, limiting their ability to explicitly store
and retrieve knowledge for various tasks. In
this paper, we propose RET-LLM a novel
framework that equips LLMs with a general
write-read memory unit, allowing them to ex-
tract, store, and recall knowledge from the text
as needed for task performance. Inspired by
Davidsonian semantics theory, we extract and
save knowledge in the form of triplets. The
memory unit is designed to be scalable, aggre-
gatable, updatable, and interpretable. Through
qualitative evaluations, we demonstrate the su-
periority of our proposed framework over base-
line approaches in question answering tasks.
Moreover, our framework exhibits robust per-
formance in handling temporal-based question
answering tasks, showcasing its ability to ef-
fectively manage time-dependent information.
1
Introduction
Large language models (LLMs) have significantly
advanced the field of natural language processing
(NLP) in recent years (Bubeck et al., 2023; Chowd-
hery et al., 2022; Touvron et al., 2023).
With
their vast parameter count and access to extensive
data, LLMs have demonstrated remarkable accu-
racy across various tasks. However, current state-
of-the-art LLMs lack a dedicated memory unit. In-
stead, they are trained to predict words based on
context, encoding knowledge implicitly in their
parameters, which differs from the ideal memory
function.
An ideal memory unit should possess certain
characteristics. Firstly, it should allow for read and
† MemLLM (Modarressi et al., 2024)
⋆Equal contribution.
Fine-tuned
LLM Model
Controller
Memory
Bill Gates and Paul Allen
are the founders of
Microsoft.
Who is the founder of
Microsoft?
Bill Gates and Paul Allen
are the founders of
Microsoft.
A
B
Figure 1: An overview of RET-LLM. A user could
prompt with (A): an informative sentence and our ap-
proach stores potent information from it inside the mem-
ory or (B): a question where previously saved informa-
tion should be utilized to generate a valid answer.
write operations, enabling the language model to
interact with stored knowledge. Scalability is also
crucial, as the memory unit should accommodate
the consistently evolving nature of knowledge. Fur-
thermore, the memory unit should not be limited
to textual documents alone; it should be capable of
acquiring knowledge from diverse sources such as
database systems. Interpretabilty is desired, grant-
ing insight into the specific knowledge required
by the LLM to solve a given task. Lastly, the in-
formation stored in the memory unit should be
aggregatable, enabling the model to combine re-
lated information across multiple documents. For
instance an LLM should be able to list all cities of
a country mentioned in multiple documents.
Previous attempts to incorporate memory into
LLMs have fallen short in capturing the complete
range of memory characteristics. For example,
(Zhong et al., 2022; Wu et al., 2022) and (Cheng
et al.) degrade the memory as the ability to re-
trieve relevant documents for a given query context,
and adding them to the context when generating
answers. Park et al. (2023) merely stores and re-
trieves previous observations and reflections of a
generative agent in a simulated environment.
To address these limitations, we introduce RET-
LLM, (Retentive LLM) a solution that endows
arXiv:2305.14322v2  [cs.CL]  24 Oct 2024
LLMs with a scalable, updatable, interpretable, and
aggregatable memory module. Our proposal in-
volves equipping language models with a memory
module, which allows them to extract knowledge
from text and save it for future reference. When
faced with a task, the LLM can query the memory
module for additional information to support its
response. The memory module supports updates
and can incorporate information from non-textual
sources such as SQL and no-SQL databases and
spreadsheets. Furthermore, it enables aggregation
of various pieces of information related to a par-
ticular concept scatterred in a huge document or
within multiple documents.
Figure 1 shows the architecture of RET-LLM. It
comprises three components: an LLM, a controller,
and a memory unit. We employ Alpaca Taori et al.
(2023), a recently released instruction-tuned lan-
guage model (LLM), and design a fine-tuning pro-
cess to enable it to acquire the following abilities:
information extraction, information lookup, and
fact-based answer generation.
Information extraction entails the identification
and extraction of triplets in the form of <concept1,
relationship, concept2> from informative sentences.
The information lookup task involves querying the
memory unit to acquire additional information con-
cerning a given concept and its associated rela-
tionships when confronted with tasks necessitating
further information. Lastly, fact-based answer gen-
eration involves generating a final answer based on
the retrieved information. The triplet-based stor-
age approach draws inspiration from the theoretical
framework of Davidsonian semantics (Davidson,
1967), which provides a foundation for represent-
ing concepts described in sentences using a triplet-
like structure of <event, subject, object>.
The memory module stores the triplets and their
vector representations. During retrieval, it first
searches for an exact match of the query text and
resorts to a fuzzy search based on vector represen-
tations if no exact match is found. For efficient
fuzzy search and retrieval, we employ LSH-based
hashing of vector representations. The controller
acts as an interface, automating interactions be-
tween users, the LLM, and the memory module,
ensuring a seamless interaction experience with an
intelligent chat system.
Our proposed approach offers several advantages
over previous methods. It enables LLMs to explic-
itly store and retrieve knowledge, which is crucial
for real-world NLP applications. By incorporating
explicit knowledge storage and retrieval, we gain
better understanding of the workings of these mod-
els and the knowledge they rely on to solve tasks.
The use of an external memory unit separate from
the LLM ensures scalability and easy modification
of stored information. The fuzzy search technique
enables efficient retrieval of relevant information,
even in the absence of exact matches. Storing in-
formation in triplets facilitates the generation of
precise and comprehensive solutions, particularly
when data aggregation is necessary. Lastly, the
memory module allows for easy incorporation of
information from diverse sources and accommo-
dates changing facts over time.
Over a qualitative evaluation using question an-
swering examples, we demonstrate cases where a
comparable LLM such as Alpaca-7B fails to re-
turn a correct answer. We show that this short-
coming occurs while the model has access to all
the information required for generating a valid an-
swer. However, in our proposed approach after
storing the extractable knowledge from the context,
the RET-LLM shows its capability in answering a
question without the need of reinputting the con-
text. We also demonstrate that RET-LLM could
handle temporal based QA examples. Since it is
equipped with a modifiable memory which could
handle temporal facts.
2
Related Works
Prior works in the field have explored incorporating
relevant context into large language models (LLMs)
by retrieving and adding relevant documents to the
task’s context. Zhong et al. (2022) propose training
LLMs with memory augmentation by introducing
trainable memory units that are optimized during
the training process. Wu et al. (2022) presents
the Memorizing Transformer, which can attend to
longer documents during inference. This approach
stores (Key, Value) pairs, extracted from a trans-
former layer, in a memory and retrieves relevant
pairs to add them to the current context during gen-
eration. (Cheng et al.) encode each documents,
save them, and retrieve relevant documents based
on the current context. In contrast to these ap-
proaches, our method offers improved scalability
as we do not modify the architecture of the LLM.
Instead, we suggest extracting and saving infor-
mation from documents, allowing for the aggrega-
tion of extracted information from multiple sources.
This enables us to provide more relevant and con-
cise retrieved information that is closely aligned
with the specific question being addressed.
Park et al. (2023) utilizes an LLM within a gen-
erative agent framework to facilitate the storage
and dynamic retrieval of a comprehensive record
of the agent’s experiences using natural language.
However, there exists a fundamental distinction be-
tween their architecture and ours. In Park’s frame-
work, the memory component is an inherent part of
the agent itself, while the LLM serves as an exter-
nal tool employed solely for planning the agent’s
behaviors. Consequently, the LLM lacks control
over the specific content to be stored and retrieved
within the agent’s memory.
Dhingra et al. (2022) contribute to the field by
curating a dataset specifically designed to differenti-
ate between temporal and non-temporal facts. They
propose training language models on temporally
annotated data to enhance their temporal aware-
ness. This work aligns with our research focus on
addressing temporal information challenges. How-
ever, in our proposed solution, we address these
challenges by introducing an updatable memory
module.
Schick et al. (2023) present a methodology that
empowers LLMs to leverage external tools by gen-
erating API calls to access additional functionali-
ties, such as using a calculator for task execution.
Our work shares similarities with their approach
in terms of teaching the LLM to utilize an external
tool. However, it should be noted that our focus
lies on incorporating a more intricate and influen-
tial tool, namely the memory module, which has
the potential to significantly impact the LLM’s out-
put.
3
Approach
We aim to design a RET-LLM where the user can
perform two actions: (1): Provide one or a series
of informative statements where the RET-LLM
should be able to memorize the containing informa-
tion. Previous methods perform this task by either
training/fine-tuning the LLM over the provided doc-
ument or creating a vector representation for the
document and storing the representation. (2): Ask-
ing related questions which the RET-LLM would
answer based on the stored memory. All these ac-
tions should function in a seamless setting where
the user should only interact in natural language.
Our RET-LLM is constituted by three main com-
ponents: (1) Controller, (2): Fine-tuned LLM &
(3): Memory. As shown in Figure 1, the controller
moderates the flow of information between the
user, the LLM and the memory. The LLM acts
as a processing unit, where it receives the texts
passed by the controller and figures where it needs
to invoke a memory call or not. Since the LLM
operates with text, inspired by Schick et al. (2023),
we standardized the memory calls by implement-
ing a text-based API schema. Therefore the LLM
could generate memory API calls and the controller
could apply the LLM API calls to the memory. In
our setting, the memory stores data in triplets by
using a three-columned table. This is based on
the theoretical framework of Davidsonian seman-
tics (Davidson, 1967), where concepts described
in sentences could be stored in a structure of <first
argument, relation, second argument>.
In the following we describe RET-LLM in more
detail. The memory-API, how we finetune the
LLM to become capable of these calls and the mem-
ory structure.
3.1
Memory Structure
Each triplet defines a relationship between two
arguments with the following format: ⟨t1, t2, t3⟩
where t1 is the first argument, t2 is the rela-
tion and t3 is the second argument in the rela-
tionship.
For instance in the sentence: “Mark
Zuckerberg is the CEO of Meta Inc.”
the
informative triplet that could be extracted is:
(Mark Zuckerberg, CEO, Meta Inc.).
To store these triplets we use a three-columned
table where each column is associated with each
part of the triplet. Alongside saving the texts, we
store the average representations so that the mem-
ory could also handle queries which have seman-
tically similar words. If the memory module fails
to find the exact text in the table, it checks for simi-
lar texts by comparing the vector representation of
the query text with vector representations of text
peices already stored in the dataset. Therefore for
every ti the mean representation retrieved by the
LLM (hAV G(ti)) is stored in a Locality-Sensitive
Hashing (LSH) table. The reason of utilizing LSH
is to reduce the computation required for finding
similar representations. Without a hash table for
a given query representation, the distances to all
of the stored representations should be computed
which would be a computationally-expensive task.
Fine-tuned
LLM Model
Controller
Memory
Bill Gates and Paul Allen
are the founders of
Microsoft.
Bill Gates and Paul Allen are the
founders of Microsoft.
[MEM_WRITE{Bill Gates>>founder>>Microsoft}]
[MEM_WRITE{Paul Allen>>founder>>Microsoft}]
{Bill Gates>>founder>>Microsoft}
{Paul Allen>>founder>>Microsoft}
1
2
3
(a) Memory-Write scenario: (1) Controller passes the input to the LLM (2) which generates the appropiate memory write
call. (3) The controller gives the data (and their average represntations) to the memory to be stored.
Fine-tuned
LLM Model
Controller
Memory
Who is the founder of
Microsoft?
Who is the founder of Microsoft?
[MEM_READ{>>founder>>Microsoft}:
{>>founder>>Microsoft}:
{Bill Gates>>founder>>Microsoft}
{Paul Allen>>founder>>Microsoft}
...{Bill Gates>>founder>>Microsoft};{Paul
Allen>>founder>>Microsoft}]
Bill Gates and Paul Allen are the
founders of Microsoft.
Bill Gates and Paul Allen
are the founders of
Microsoft.
1,2
5,6
3,4
7
(b) Memory-Read scenario: (1) Controller passes the question to the LLM (2) which generates the appropiate memory read
call. (3) The controller apply the query on the memory with the given search terms from the LLM. (4) The memory returns
the query results which are (5) forwarded back to the LLM. (6) The LLM generates the answer to the question using the
query results and (7) the answer would be returned back to the user.
Figure 2: A visualization of the process in both read- and write-based inputs.
Handling Memory Queries.
In a memory query,
one or two of the triplet parameters should be pro-
vided as input:
Q ∈{⟨q1⟩, ⟨q2⟩, ⟨q3⟩, ⟨q1, q2⟩, ⟨q1, q3⟩, ⟨q2, q3⟩}
Where qi is the search term for the i-th parameter
in the stored tuples. Before retrieving the query
results, each search term is checked For a given Q,
first the memory checks whether the search terms
(qi) have an exact match in the storage table. If qi
does not exist in the stored terms, we use its average
representation hAV G(qi) and the LSH table for an
alternative term (˜qi) that has an exact match in
out memory table. Possibly, the LSH table may not
find an alternative term for the given representation,
therefore the query would not have a result: Q →∅.
In any case (exact match or similar match), the
query might have multiple matches in the data table
(qi = ti). In this case all resulting triplets would be
returned as the query output.
3.2
Memory-API & Dataflow
To enable communication between the memory and
the LLM, we design an API schema for memory
read and write functions. This API allows the con-
troller to understand when the LLM is calling the
memory and what parameters should be passed.
Based on the triplets discussed in the previous sec-
tion, the two memory calls are as the following:
• [MEM_WRITE{t1»t2»t3}]: This structure is for
storing a triplet ⟨t1, t2, t3⟩. Depending on the
prompt, multiple write calls could be sequen-
tially generated by the LLM to store multiple
triplets extracted from a text.
• [MEM_READ{_»_»_}: {t1»t2»t3};...] : In
a memory read, as shown in the API, there are
three placeholders that based on Q atleast one
of them should be filled with the search terms.
Based on the query results from the memory,
one or a list of triplets could be returned as
shown in the highlighted segment.
Figure 2 demonstrates how RET-LLM operates
using the memory-API. Depending on the input
given by the user, RET-LLM either have to read
or write information from or to the memory. If the
user prompt an informative statement (or ideally a
full document), it would be memory write scenario.
On the other hand, by having a question in the input,
we consider this to be a memory read case. In both
cases the user input is the first input to RET-LLM
that is passed on to the LLM.
Based on the given input the LLM infers and
generates the relevant API call. With a memory
write case, after the API call is generated the con-
troller detects it and invoke a memory storation
function with the given parameters. The memory
receives the data in a triplet format and stores it for
future usage. If a memory read call is generated by
the LLM, the controller also detects it and pauses
the model’s sequence generation for the memory
retrieval. It uses the parameters given inside the
read call as the query terms and passes them to the
memory. The memory lists all stored triplets that
feature the given search terms (or a semantically
similar version of them according to §3.1) and re-
turn the results back to the controller. Using the
API discussed in the beginning of this section, the
read results are listed after the call so that the LLM
could use them to produce a naturally sounded an-
swer. After the answer is produced it is returned
back to the user.
As the controller is in between of the user and the
LLM, it could hide the whole memory-API schema.
This would make the user feel an end-to-end simple
language modeling experience without knowing
the memory functionality behind the scene.
3.3
Finetuning the LLM
In this part we discuss how the LLM is finetuned
to be capable of generating memory-API calls. In
the end the LLM should be capable of detecting
which type of memory call (read or write) it should
provoke based on the input. As stated in Section
3.2, the LLM’s input may have one of the two
previously discussed structures depending on the
memory function. Therefore the LLM should be
able to generate and handle this API to store or read
the relevant information. To this end, we develop a
synthetic dataset to train the LLM. The synthetic
task is to learn the relationships of the discussed
people with the respective corporations. Based
on the stored information, RET-LLM should be
capable of answering any questions regarding the
people, the corporations or the relationships.
We use a set of firstname and lastnames to
generate a synthetic population, called P. Each
person from this population per
∈
P could
have only one relationship from the following
list: rel ∈R = {employment, manager, investor,
founder, customer} with an organization org ∈
O.
Where O is a set of corporation names.
Hence, each triplet would be as: (per, rel, org).
For instance: ⟨Dominick Alphonso, employment,
BMW⟩.1 Based on this triplet we can build three
triplet-specific questions:
• Q
=
⟨per⟩, e.g.
“Who is Dominick
Alphonso?”
• Q
=
⟨per, org⟩, e.g.
“How Dominick
Alphonso is related to BMW?”
• Q = ⟨per, rel⟩, e.g. “Dominick Alphonso is
employed by which company?”
and the answer to all above should be “Dominick
Alphonso is employed by BMW.”. Alongside these
questions three other types of questions could be
asked that could be relevant to multiple triplets:
• Q = ⟨rel⟩, e.g. “Who are the employees?”
• Q = ⟨org⟩, e.g. “Who are related to BMW?”
• Q = ⟨rel, org⟩, e.g. “Who are employed by
BMW?”
Unlike the first three, each of these questions could
have multiple persons related to the answer. For
each of these questions we expect the model an-
swer the questions without any extra information
(e.g. stating the corporation of employment when
its not asked). To create a training data instance
from these questions based on the memory-API,
we use the templates stated in Table 1. During fine-
tuning the Question, API query (with the MEM_READ
command), API Response and the answer are con-
catenated as the data input for the LLM. However,
the langauge modeling loss is only applied to the
API query and Answer sections. Since these two
segments are the text sequences that the LLM is ex-
pected to generate based on the other two segments
(Question & API Response) that are provided by
the controller.
1Even though the corporation names are real, the people
names are entirely random generated. No identification with
actual persons is intended or should be inferred.
Query Type
Question
API Query
API Response
Answer
⟨per⟩
Who is per?
{per»»}:
{per»rel»org}
per is rel to org.
⟨per, org⟩
How per is related to org?
{per»»org}:
{per»rel»org}
per is rel to org.
⟨per, rel⟩
per is rel which company?
{per»rel»}:
{per»rel»org}
per is rel to org.
⟨org⟩
Who are related to org?
{»»org}:
{per1»rel1»org};{per2»rel2»org};...
[per1, per2, ...] is\are related to org.
⟨rel⟩
Who are the rel?
{»rel»}:
{per1»rel»org1};{per2»rel»org2};...
[per1, per2, ...] is\are rel.
⟨org, rel⟩
Who are rel org?
{»rel»org}:
{per1»rel»org};{per2»rel»org};...
[per1, per2, ...] is\are rel to org.
Table 1: Memory read data examples for finetuning. The first three types of questions are based on a single triplet
therefore the API response would be only one triplet. However the second three may have multiple relevant tiplets
stored in the memory as shown in their API-Resonse. Thus, the answer should combine the triplets data into a single
sentence. [per1, per2, ...] is the placeholder of the names written sequentially in a natural way. For instance: “Dirk
Alosa, Ty Baumkirchner, and Vera Bayless”
Triplet(s)
Statement
API Write Call(s)
[⟨per1, rel, org⟩, ⟨per2, rel, org⟩, ...]
[per1, per2, ...] is\are rel to org.
[MEM_WRITE{per1»rel1»org}][MEM_WRITE{per2»rel2»org}]...
Table 2: Memory write data example structure for finetuning.
As we also need informative examples where
have MEM_WRITE calls, we use a similar strategy by
using the population, organizations and relations
that were previously defined (P, Q, R). Based on
the memory-API, in a memory write scenario the
RET-LLM receives a sentence which here con-
tains a relationship information and then the LLM
should generate the corresponding memory write
calls.
In our dataset we opted to build exam-
ples where it states about multiple people whom
have the same relationship with the same com-
pany: (peri, rel, org). The template for the mem-
ory write data examples are shown in Table 2. Sim-
ilar to the question-based examples, the statement
and the API call are concatenated to form the full
input sequence. Also the loss function is applied
only to the API segment, since the first part is pro-
vided by the controller.
We opted to use the Instruction-following
Alpaca-7B model (Taori et al., 2023) as a base
model for our finetuning. To execute the training
in a resource limited setup, we use low-rank adap-
tation (LoRA) (Hu et al., 2022). 2 This parameter
efficient measure allows us to finetune the base
model on a single A6000 48GB GPU.
4
Qualitative Results
In this part, we present the internal process and final
output on multiple evaluation examples. These
examples were generated with the same procedure
stated in §3.3. First to demonstrate the importance
of our approach, we provide the same example to
2The code for finetuning a llama-based model using LoRA
is available at: github.com/tloen/alpaca-lora
our base model (Alpaca-7B) in a zero-shot setting.
The input would be a short instruction for the task,
the informative sentences from the example and in
the end is the question. As shown in Figure 3, the
zero-shot result from the instruction tuned model
is clearly incorrect. While the model does have all
the information in its context, its still produces an
incorrect response.
In thie same example, the RET-LLM first stores
the extracted triplets from the examples into the
memory. After storing the extracted relationships,
the RET-LLM could respond to the same question
even without having the information in the input.
With the help of the memory-API and the memory
itself, the relevant triplet is found. The LLM man-
ages to answer correctly after appending the query
result to the memory call.
One potential use cases of our approach is in
answering questions that have a temporal context.
For example, the presidency of the United States
undergoes a change every 4 to 8 years. A normal
PLM model answers the question about the presi-
dency based on its own training data. While model
retraining or parameter editing has its own chal-
lenges, our approach could provide an easy and
interpretable solution for this issue (Figure 4).
5
Conclusion & Future Work
In this work, we introduced a RET-LLM capable
of storing information and retrieving it in further
use. With a triplet based memory structure, infor-
mation are stored in relationships between two ar-
guments with a known relation. The memory could
be utilized via a memory-API which is generated
: Cyrus Alfred, Tia Batres, and Pasquale Ballif are customers of Pfizer.
Evaluation Example #1:
[MEM_WRITE{Cyrus Alfred>>customer of>>Pfizer}][MEM_WRITE{Tia Batres>>customer of>>Pfizer}][MEM_WRITE{Pasquale
Ballif>>customer of>>Pfizer}]
LLM Response to Controller:
{Cyrus Alfred>>customer of>>Pfizer}
{Tia Batres>>customer of>>Pfizer}
{Pasquale Ballif>>customer of>>Pfizer}
Memory
Controller
: Dorothea Altemus is employed by Pfizer.
[MEM_WRITE{Dorothea Altemus>>employed by>>Pfizer}]
LLM Response to Controller:
{Dorothea Altemus>>employed by>>Pfizer}
Memory
Controller
: Who are employed by Pfizer?
[MEM_READ{>>employed by>>Pfizer}:
LLM Response to Controller:
Memory
Controller
{Dorothea Altemus>>employed by>>Pfizer}
LLM Full Input: (User Prompt + MEM_READ Call + Memory result passed by the Controller)
Who are employed by Pfizer?[MEM_READ{>>employed by>>Pfizer}:{Dorothea Altemus>>employed by>>Pfizer}]
Dorothea Altemus is employed by Pfizer.
LLM ﬁnal output to the User:
Evaluation Example #1 (Zero-Shot Setting - Alpaca-7B):
Cyrus Alfred, Tia Batres, and Dorothea Altemus.
LLM output to the User:
: You will be presented with one or a series of sentences about some people
and their relationship with a company. After that, for any given question you
should be capable of answering that based on the previous sentences.
Cyrus Alfred, Tia Batres, and Pasquale Ballif are customers of Pfizer. Dorothea
Altemus is employed by Pfizer.
Question: Who are employed by Pfizer?
Answer:
Instruction
Relationship sentences
Question and prompt for the answer
Figure 3: An example that has an incorrect result in a zero-shot setting and a correct one in our approach. Note that
in the zero-shot setting the model has direct access to the information required for answering the question in its
input and still end up with an incorrect answer. However, in our approach each of the user prompts could be given
to the RET-LLM in separately. Another example is mentioned in the appendix Figure 5.
QA Example (Alpaca-7B):
Barack Obama.
LLM output to the User:
: Question: Who is the president of the United States?
Answer:
: Who is the president of the United States?
[MEM_READ{>>president of>>United States}:
LLM Response to Controller:
QA Example:
Memory
Controller
{Joe Biden>>president of>>United States}
LLM Full Input: (User Prompt + MEM_READ Call + Memory result passed by the Controller)
Who is the president of the United States?[MEM_READ{>>president of>>United States}:{Joe Biden>>president
of>>United States}]
Joe Biden is the president of the United States.
LLM ﬁnal output to the User:
Figure 4: Asking a question which requires temporal context usually leads to an outdated answer as shown here
with Alpaca. However, in our RET-LLM with the aid of a modifiable memory, these questions could be answered
by simply providing a updated memory entry.
by a finetuned LLM. Using a controller, all compo-
nents could communicate with each other and the
user would interact with the controller being unbe-
known of the behind process. We have shown that
the LLM generates the proper API calls in some
question answering examples without having the
information in its input context. As this work is
still under development, in our next revision we
will add a more in-detail empirical evaluation, pre-
ferrably on a real dataset. We also seek to improve
our finetuning method to a more generalized setting
so that it could be capable of working with more
types of informative relations.
References
Sébastien Bubeck, Varun Chandrasekaran, Ronen El-
dan, Johannes Gehrke, Eric Horvitz, Ece Kamar,
Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund-
berg, et al. 2023. Sparks of artificial general intelli-
gence: Early experiments with gpt-4. arXiv preprint
arXiv:2303.12712.
Xin Cheng, Yankai Lin, Dongyan Zhao, and Rui Yan.
Language model with plug-in knowldge memory.
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,
Maarten Bosma, Gaurav Mishra, Adam Roberts,
Paul Barham, Hyung Won Chung, Charles Sutton,
Sebastian Gehrmann, Parker Schuh, Kensen Shi,
Sasha Tsvyashchenko, Joshua Maynez, Abhishek
Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-
odkumar Prabhakaran, Emily Reif, Nan Du, Ben
Hutchinson, Reiner Pope, James Bradbury, Jacob
Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,
Toju Duke, Anselm Levskaya, Sanjay Ghemawat,
Sunipa Dev, Henryk Michalewski, Xavier Garcia,
Vedant Misra, Kevin Robinson, Liam Fedus, Denny
Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim,
Barret Zoph, Alexander Spiridonov, Ryan Sepassi,
David Dohan, Shivani Agrawal, Mark Omernick, An-
drew M. Dai, Thanumalayan Sankaranarayana Pil-
lai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,
Rewon Child, Oleksandr Polozov, Katherine Lee,
Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark
Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy
Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,
and Noah Fiedel. 2022. Palm: Scaling language mod-
eling with pathways.
Donald Davidson. 1967. The logical form of action
sentences, reprinted in d. davidson (1980) essays on
actions and events.
Bhuwan Dhingra, Jeremy R. Cole, Julian Martin
Eisenschlos, Daniel Gillick, Jacob Eisenstein, and
William W. Cohen. 2022. Time-aware language mod-
els as temporal knowledge bases. Transactions of the
Association for Computational Linguistics, 10:257–
273.
Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-
Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu
Chen. 2022. LoRA: Low-rank adaptation of large
language models. In International Conference on
Learning Representations.
Ali Modarressi, Abdullatif Köksal, Ayyoob Imani,
Mohsen Fayyaz, and Hinrich Schütze. 2024. Mem-
llm: Finetuning llms to use an explicit read-write
memory. arXiv preprint arXiv:2404.11672.
Joon Sung Park, Joseph C O’Brien, Carrie J Cai, Mered-
ith Ringel Morris, Percy Liang, and Michael S
Bernstein. 2023.
Generative agents: Interactive
simulacra of human behavior.
arXiv preprint
arXiv:2304.03442.
Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta
Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola
Cancedda, and Thomas Scialom. 2023. Toolformer:
Language models can teach themselves to use tools.
arXiv preprint arXiv:2302.04761.
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann
Dubois, Xuechen Li, Carlos Guestrin, Percy Liang,
and Tatsunori B. Hashimoto. 2023. Stanford alpaca:
An instruction-following llama model.
https://
github.com/tatsu-lab/stanford_alpaca.
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
Martinet, Marie-Anne Lachaux, Timothée Lacroix,
Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal
Azhar, Aurelien Rodriguez, Armand Joulin, Edouard
Grave, and Guillaume Lample. 2023. Llama: Open
and efficient foundation language models.
Yuhuai Wu, Markus N Rabe, DeLesley Hutchins, and
Christian Szegedy. 2022. Memorizing transformers.
arXiv preprint arXiv:2203.08913.
Zexuan Zhong, Tao Lei, and Danqi Chen. 2022. Train-
ing language models with memory augmentation.
In Proceedings of the 2022 Conference on Empir-
ical Methods in Natural Language Processing, pages
5657–5673, Abu Dhabi, United Arab Emirates. As-
sociation for Computational Linguistics.
A
Extra Evaluation Example
: Mozella Baima and Modesto Baichan are employees of ExxonMobil.
Evaluation Example #2:
[MEM_WRITE{Mozella Baima>>employed by>>ExxonMobil}][MEM_WRITE{Modesto Baichan>>employed by>>ExxonMobil}]
LLM Response to Controller:
{Mozella Baima>>employed by>>ExxonMobil}
{Modesto Baichan>>employed by>>ExxonMobil}
Memory
Controller
: Maryjane Bachand and Willian Beasmore are employees of BMW.
[MEM_WRITE{Maryjane Bachand>>employed by>>BMW}][MEM_WRITE{Willian Beasmore>>employed by>>BMW}]
LLM Response to Controller:
Memory
Controller
: Who are related to BMW?
[MEM_READ{>>>>BMW}:
LLM Response to Controller:
Memory
Controller
{Maryjane Bachand>>employed by>>BMW}
{Willian Beasmore>>employed by>>BMW}
{Willian Banik>>customer of>>BMW}
LLM Full Input: (User Prompt + MEM_READ Call + Memory result passed by the Controller)
Who are related to BMW?[MEM_READ{>>>>BMW}:{Maryjane Bachand>>employed by>>BMW};{Willian Beasmore>>employed
by>>BMW};{Willian Banik>>customer of>>BMW}]
Willian Beasmore, Maryjane Bachand, and Willian Banik are related to BMW.
LLM ﬁnal output to the User:
{Maryjane Bachand>>employed by>>BMW}
{Willian Beasmore>>employed by>>BMW}
: Willian Banik is a customer of BMW.
[MEM_WRITE{Willian Banik>>customer of>>BMW}]
LLM Response to Controller:
Memory
Controller
{Willian Banik>>customer of>>BMW}
Evaluation Example #2 (Zero-Shot Setting - Alpaca-7B):
Mozella Baima, Modesto Baichan, Maryjane Bachand, and Willian Beasmore are all employees of BMW.
LLM output to the User:
: You will be presented with one or a series of sentences about some people
and their relationship with a company. After that, for any given question you
should be capable of answering that based on the previous sentences.
Mozella Baima and Modesto Baichan are employees of ExxonMobil. Maryjane Bachand
and Willian Beasmore are employees of BMW. Willian Banik is a customer of BMW.
Question: Who are related to BMW?
Answer:
Instruction
Relationship sentences
Question and prompt for the answer
Figure 5: Another evaluation example that has an incorrect result in a zero-shot setting and a correct one in our
approach.
